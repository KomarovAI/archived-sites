# Archived Sites

Automated archive of crawled websites exported from Kestra workflows.

## Structure

Each website is stored in its own directory:

```
archived-sites/
â”œâ”€â”€ site1/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ page1.html
â”‚   â”œâ”€â”€ page2.html
â”‚   â””â”€â”€ assets/
â”‚       â”œâ”€â”€ images/
â”‚       â”œâ”€â”€ css/
â”‚       â””â”€â”€ js/
â”œâ”€â”€ site2/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ ...
â””â”€â”€ site3/
    â””â”€â”€ ...
```

## Workflow

1. **Crawler**: `full-site-crawler` workflow crawls websites â†’ saves to PostgreSQL
2. **Export**: `db-to-github-export` workflow exports from PostgreSQL â†’ pushes to this repo

## Automation

- Commits are automated by Kestra workflow
- Each export creates commit: `Auto-export site {name} from DB [{timestamp}]`
- Sites are versioned through Git history

## Source

Exported from: [kestra-docker-starter](https://github.com/KomarovAI/kestra-docker-starter)

## Usage

Browse any site directory to view archived HTML files. All sites are static and can be:
- Viewed directly in GitHub
- Downloaded for offline browsing
- Deployed to static hosting (GitHub Pages, Netlify, etc.)

## Privacy

ðŸ”’ This repository is **private**. Only authorized users can access archived sites.
